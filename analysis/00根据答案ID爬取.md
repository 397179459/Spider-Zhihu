### 根据答案ID爬取

#### 1. 分析URL

单纯的分析这个答案的结构，多观察几个知乎回答的URL，很容易就发现URL已经包含了我们需要的所有信息，`https://www.zhihu.com/question/348913438/answer/844072209` question后面的是问题ID（以后叫 qid ），answer 后面的是答案ID（以后叫aid）。

#### 2. 网页结构

注意直接打开答案的URL和打开问题的URL，得到的网页结构是不一样的，知乎er 应该知道如果点开通过答案URL跳转的网页，答案是全部显示的；但是如果通过问题URL跳转的，默认只有第一个回答是全部展开的，这个后面会详解。

所以这里我就想到用 `urllib` + `BeautifulSoup4`。先写请求URL和soup解析的代码

[![gJdZgH.png](https://z3.ax1x.com/2021/05/09/gJdZgH.png)](https://imgtu.com/i/gJdZgH)


##### 当然我们为了追根溯源，所以就先找找问题和作者都是什么

- 这里的方法不止我写的这种，因为问题和作者在网页中出现不止一次，因为是现学`BeautifulSoup4`，很多定位方法不熟悉，所以我是用我能找到的方法实现。至少测试过几百个回答，都能实现需求。

我们用F12分析一下网页结构，搜索问题名称，很容易就看到了这个`QuestionHeader-title`类的文本是问题名称。利用soup 定位。

[![gJdKbt.png](https://z3.ax1x.com/2021/05/09/gJdKbt.png)](https://imgtu.com/i/gJdKbt)

[![gJduDI.png](https://z3.ax1x.com/2021/05/09/gJduDI.png)](https://imgtu.com/i/gJduDI)

再找作者，搜索作者，找到这个，利用soup定位。

[![gJdQVP.png](https://z3.ax1x.com/2021/05/09/gJdQVP.png)](https://imgtu.com/i/gJdQVP)

[![gJdiE6.png](https://z3.ax1x.com/2021/05/09/gJdiE6.png)](https://imgtu.com/i/gJdiE6)

需要注意的是，win系统命名是不能包含有些字符的，所以我用了正则提取文字内容，否则保存图片的时候会报错。详见`re_only_chinese`函数。

##### 最主要是找图片地址

看到了所有图片都是在<figure>标签下的<img>标签中，而且都是可见的，不是滚动动态加载的。因为每个标签中都有好几个图片地址，而且标签的属性基本一致，`class`都包含了`origin_image zh-lightbox-thumb lazy`，所以很容易定位。

- 特例：后面的测试中就遇到过一次，不过根据我下载的上万张来看，只是极个别的，我也不知道为什么那张图片`class`不是`origin_image zh-lightbox-thumb lazy`，而是`content_image lazy`，所以后面代码优化了一点，详见 `url_answer`函数。

[![gJdnKA.png](https://z3.ax1x.com/2021/05/09/gJdnKA.png)](https://imgtu.com/i/gJdnKA)

不过我们肯定是要下载高清原图的，所以我们拿一个出来分析，其中`src`是保存缩略图的，比较小，其余几个都差不多，我通过分别下载，确定原图是保存在`data-actualsrc`中的。

```html
<img src="https://pic1.zhimg.com/80/v2-d112b8feb0ea4f0ae0fc910d8be1a929_720w.jpg?source=1940ef5c" data-caption="" data-size="normal" data-rawwidth="1776" data-rawheight="2231" data-default-watermark-src="https://pic1.zhimg.com/50/v2-a700093ae57dda785bb4a28b905ec4ca_hd.jpg?source=1940ef5c" class="origin_image zh-lightbox-thumb lazy" width="1776" data-original="https://pic2.zhimg.com/v2-d112b8feb0ea4f0ae0fc910d8be1a929_r.jpg?source=1940ef5c" data-actualsrc="https://pic1.zhimg.com/50/v2-d112b8feb0ea4f0ae0fc910d8be1a929_hd.jpg?source=1940ef5c" data-lazy-status="ok">
```

代码实现：先用soup找到所有的img标签，然后再取出每个图片地址，用遍历的形式添加到一个我们定义的图片URL列表中。bingo

[![gJdECD.png](https://z3.ax1x.com/2021/05/09/gJdECD.png)](https://imgtu.com/i/gJdECD)

#### 3. 图片下载

之前已经得到了我们需要的图片URL列表，所以我们只需要用`urlretrieve`方法下载图片即可，这里稍微复杂的一点的是图片的保存地址，因为其他的爬虫都会用到这个模块，所以功能稍微复杂点，具体见`download_pic`函数。

后面还用到了多线程图片下载，已经不属于爬虫分析的部分了，这里不再赘述，详见`thread_pool_download`函数。

